{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN DVBS2X Implementation",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYABXLAiT77okS+Nu7pczf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG851CQXAexf"
      },
      "source": [
        "#to do \n",
        "#LSTM -- done\n",
        "#use GPU for training -- (issues with input and model being on different devices)\n",
        "#stack real and imaginary into one array -- (done)\n",
        "#train -- (done)\n",
        "#test -- (done)\n",
        "#save output -- (done) need to fix loop for doing that\n",
        "#import back to matlab (done)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqy9OHMcQmDS"
      },
      "source": [
        "#import libraries \n",
        "import numpy as np\n",
        "\n",
        "#pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
        "\n",
        "#for reading from csv\n",
        "import csv \n",
        "\n",
        "#for plotting \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ipw6bAIucuj"
      },
      "source": [
        "#read input and labels into variables \n",
        "with open('train.csv', 'r') as f: \n",
        "    data = list(csv.reader(f, delimiter=\",\"))\n",
        "\n",
        "data = np.array(data, dtype = 'float32') #convert to numpy array\n",
        "data = torch.from_numpy(data) #convert to torch tensor\n",
        "\n",
        "with open('labels.csv', 'r') as f:\n",
        "    labels = list(csv.reader(f, delimiter=\",\"))\n",
        "\n",
        "labels = np.array(labels, dtype = 'float32') #convert to numpy array\n",
        "labels = torch.from_numpy(labels) #convert to torch tensor \n",
        "\n",
        "with open('test.csv', 'r') as f: \n",
        "    test = list(csv.reader(f, delimiter = \",\"))\n",
        "\n",
        "test = np.array(test, dtype = 'float32') #convert to numpy array\n",
        "test = torch.from_numpy(test) #convert to torch tensor"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80yYn4kC8EoA"
      },
      "source": [
        "#create a custom dataset with input and labels \n",
        "class CustomDS(Dataset):\n",
        "    def __init__(self, input, labels):\n",
        "        self.labels = labels\n",
        "        self.input = input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        data = self.input[idx]\n",
        "        return data, label"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClXRw-Wnt4XN"
      },
      "source": [
        "ds = CustomDS(data, labels) #create a dataset with (corrupted) input and corresponding labels\n",
        "test_ds = CustomDS(test, test)  #create a test datset, ignore the repeated test variable. Will not be used\n",
        "length = len(ds) \n",
        "train_size = int(0.7*length) \n",
        "val_size = int(0.3*length)\n",
        "\n",
        "#get train, validation, and test sets\n",
        "train_ds, val_ds = random_split(ds, [train_size, val_size])\n",
        "\n",
        "#create data loaders\n",
        "batch_size = 10; \n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
        "val_dl = DataLoader(val_ds, batch_size, shuffle = True)\n",
        "test_dl =DataLoader(test_ds, batch_size, shuffle = False)  #do not shuffle, very important"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuVCptcFxYWm"
      },
      "source": [
        "#define NN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self): \n",
        "    #layer definition here\n",
        "        super().__init__()\n",
        "        self.layers1 = nn.Sequential(\n",
        "            #Conv1\n",
        "            nn.Conv1d(1, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #Conv2\n",
        "            nn.Conv1d(10, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(20, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.lstm1 = nn.LSTM(20, 10, 1, batch_first = True)\n",
        "        self.lstm2 = nn.LSTM(10, 5, 1, batch_first = True)\n",
        "        self.lstm3 = nn.LSTM(5, 10, 1, batch_first = True)\n",
        "        self.lstm4 = nn.LSTM(10, 20, 1, batch_first = True)\n",
        "        \n",
        "        self.layers2 = nn.Sequential(\n",
        "            #Conv3\n",
        "            nn.Conv1d(20, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #Conv4\n",
        "            nn.Conv1d(10, 1, 1)\n",
        "        )   \n",
        "       \n",
        "    def forward(self, x): \n",
        "        x = torch.unsqueeze(x, 1) #need this so input is of size (N, Cin, L)\n",
        "        #define hidden state and cell state\n",
        "\n",
        "        #lstm1\n",
        "        h_0 = torch.zeros(1, 10, 10) #(num_layers, batch_size, hidden_state)\n",
        "        c_0 = torch.zeros(1, 10, 10)\n",
        "\n",
        "        h_1 = torch.zeros(1,10, 5)\n",
        "        c_1 = torch.zeros(1,10,5)\n",
        "\n",
        "        h_2 = torch.zeros(1,10, 10)\n",
        "        c_2 = torch.zeros(1, 10, 10)\n",
        "\n",
        "        h_3 = torch.zeros(1, 10, 20)\n",
        "        c_3 = torch.zeros(1, 10, 20)\n",
        "        \n",
        "        out = self.layers1(x) #convolution\n",
        "\n",
        "        out = torch.reshape(out, (10, 100, 20))\n",
        "        \n",
        "        out, (h_n, c_n) = self.lstm1(out, (h_0, c_0)) #pass through lstm1 (h_n = [1,10,10])\n",
        "\n",
        "        out,(h_n, c_n) = self.lstm2(out, (h_1, c_1))\n",
        "\n",
        "        out,(h_n, c_n) = self.lstm3(out, (h_2, c_2))\n",
        "\n",
        "        out, (h_n, c_n) = self.lstm4(out, (h_3, c_3))\n",
        "\n",
        "        out = torch.reshape(out, (10, 20, 100))\n",
        "    \n",
        "        out = self.layers2(out) #convolution\n",
        "        return out\n",
        "\n",
        "    def training_step(self, x):\n",
        "        inputs, labels = x #get input and labels from batch of data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        out = self(inputs) #forward pass\n",
        "        loss = F.mse_loss(out, labels) #loss calculation\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, x):\n",
        "        inputs, labels = x #get input and labels from batch of data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        out = self(inputs) #forward pass\n",
        "        loss = F.mse_loss(out,labels) #loss calculation\n",
        "        acc = 1-loss #accuracy calculation\n",
        "\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs): \n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean() #Co\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()\n",
        "        \n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RqFJIixrmNG"
      },
      "source": [
        "def evaluate(model, val_dl):\n",
        "    outputs = [model.validation_step(batch) for batch in val_dl]\n",
        "    \n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oplXuZa241CL"
      },
      "source": [
        "def trainNet(epochs, lr, model, train_dl, val_dl, opt_func = torch.optim.SGD): \n",
        "    #training function for training NN\n",
        "    #inputs: \n",
        "    #epochs: number of epochs to train for\n",
        "    #lr: learning rate for optimizer\n",
        "    #model: model to be traine on\n",
        "    #train_dl: data loader with inputs and labels to train on\n",
        "    #val_dl: validation loader \n",
        "    #opt_func: optimizer function\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    history = [] #recording epoch-wise results\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "    #enter training loop\n",
        "        for batch in train_dl:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward() #backprop\n",
        "            optimizer.step() #step forward in optimizer based on backgrop results\n",
        "            optimizer.zero_grad() #zero the gradients from training step\n",
        "\n",
        "        #validation phase\n",
        "        result = evaluate(model, val_dl)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "\n",
        "    return history\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR698MeB4CEq"
      },
      "source": [
        "net = Net() #instantiate \n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYSPxBZlAb4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9acbb8-1e18-4388-f7d1-d635b5ad5e5b"
      },
      "source": [
        "history = trainNet(10, 0.0001, net, train_dl, val_dl)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Using a target size (torch.Size([10, 100])) that is different to the input size (torch.Size([10, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: Using a target size (torch.Size([10, 100])) that is different to the input size (torch.Size([10, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 0.4629, val_acc: 0.5371\n",
            "Epoch [1], val_loss: 0.4095, val_acc: 0.5905\n",
            "Epoch [2], val_loss: 0.3953, val_acc: 0.6047\n",
            "Epoch [3], val_loss: 0.3913, val_acc: 0.6087\n",
            "Epoch [4], val_loss: 0.3897, val_acc: 0.6103\n",
            "Epoch [5], val_loss: 0.3890, val_acc: 0.6110\n",
            "Epoch [6], val_loss: 0.3886, val_acc: 0.6114\n",
            "Epoch [7], val_loss: 0.3884, val_acc: 0.6116\n",
            "Epoch [8], val_loss: 0.3883, val_acc: 0.6117\n",
            "Epoch [9], val_loss: 0.3882, val_acc: 0.6118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "i9BOGqzD1ITk",
        "outputId": "f896702e-c771-4029-cfe4-33d96c4d1c5d"
      },
      "source": [
        "#plot training results\n",
        "accuracies = [result['val_acc'] for result in history]\n",
        "plt.plot(accuracies, label = 'accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "losses = [result['val_loss'] for result in history]\n",
        "plt.plot(losses, label = 'loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0443317950>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnkkDYZYksCQgotiqyRlxaqdarYl1Qca9WaNX6a7WutWq1tWpvbW212nqrXKvV6wIW1NJqtVoXtNVKwACCGyJKIigQdggkmc/vj3MSJuEEJpDJyfJ+Ph7zmDPfs33mBM57zjnfOWPujoiISF2JuAsQEZHmSQEhIiKRFBAiIhJJASEiIpEUECIiEkkBISIikRQQIi2AmfU2s5lmtt7MfhN3PQBmtsTM/ivuOiRzFBCSUa1pJ2JmN5mZm9kZKW3ZYdvADK/+ImAl0NXdr8rwukQABYRIQ5UBPzOzrCZe717AQtc3W6UJKSAkFmbW3sx+a2afhY/fmln7cFwvM/ubma0xszIze83MEuG4H5lZaXiq5X0zOypi2Qeb2fLUnbiZnWJm88LhMWZWZGbrzOxzM7ujAaU/B2wFzq3nfXUzs4fNbIWZfWJmN1TXnsY2OczMZpnZ2vD5sLD9T8D5wDVmtiHqiCzcnr82s0/D93SvmXUIxx1hZiVmdr2ZrQyP6r6Zbs1mdqGZvRtu84VmNipl1SPMbF5Y81Qzyw3nqfdvKC2H/mASlx8DhwAjgOHAGOCGcNxVQAmQB/QGrgfczL4EXAIc5O5dgGOBJXUX7O7/ATYCX09pPgd4LBy+C7jL3bsCewNPNKBuB24EfmpmORHjfwd0AwYDXwO+BUza2ULNrAfwDHA30BO4A3jGzHq6+0TgUeBX7t7Z3V+MWMRtwL4E23MfIB/4Scr4PkCvsP18YHK4PXdYs5mdDtwUtnUFTgJWpSz3DGAcMAgYBkwM2yP/hjvbDtK8KCAkLt8Ebnb3L9x9BfAz4LxwXAXQF9jL3Svc/bXw1EoV0B7Y38xy3H2Ju39Uz/IfB84GMLMuwDfCturl72Nmvdx9g7u/2ZDC3X0GsAK4ILU9PGI5C7jO3de7+xLgNynva0eOBz509/9z90p3fxx4DzhxZzOamRFco7jC3cvcfT3w32EtqW509y3u/ipBGJ2RRs0XEATTLA8scvdPUpZ5t7t/5u5lwF8JAgrq/xtKC6KAkLj0A1J3NJ+EbQC3A4uAf5jZYjO7FsDdFwGXE3yi/cLMpphZP6I9BpwanrY6FZiTsmP7DsGn7ffCUzkn7EL9NxAcBeWmtPUCciLeV34ay6u7PRoybx7QEZgdntJZQ3AqLC9lmtXuvrHOsvulUXN/oL4QBlieMrwJ6BwOR/4NpWVRQEhcPiO48FptQNhG+En2KncfTHBK48rqaw3u/pi7fzWc14FfRi3c3RcS7OiOo/bpJdz9Q3c/G9gznH+amXVqSPHu/gLBDvB7Kc0rCT45131fpWkssu72aMi8K4HNwAHuvkf46ObunVOm6V7nPVZv753VvJTgNFyD7OhvKC2HAkKaQo6Z5aY8sglO99xgZnlm1ovgfPkjAGZ2gpntE546WUtwailpZl8ys6+HRwXlBDvF5A7W+xhwGTAW+HN1o5mda2Z57p4E1oTNO1pOfX4MXFP9wt2rCK5n/NzMupjZXsCV1e9rJ54F9jWzc8Kus2cC+wN/29mM4fv4X+BOM9sTwMzyzezYOpP+zMzamdnhwAnAn9Oo+X7gajMbbYF9wml2qL6/YRrbQZoRBYQ0hWcJdubVj5uAW4EiYB4wH5gTtgEMAV4ENgBvAP/j7i8TXH+4jeBT73KCI4DrdrDexwkuur7k7itT2scBC8xsA8EF67PcfTNA2Evo8HTelLv/C3irTvOlBBfIFwOvE4TUA+Gyrzezv9ezrFUEO+2rCC4CXwOcUKfuHfkRwRHNm2a2jmD7fSll/HJgNcFRw6PAxe7+3s5qdvc/Az8P29YDTwM90qinvr+htCCm60YirZuZHQE84u4FcdciLYuOIEREJJICQkREIukUk4iIRNIRhIiIRMqOu4DG0qtXLx84cGDcZYiItCizZ89e6e55UeNaTUAMHDiQoqKiuMsQEWlRzKzuN/hr6BSTiIhEUkCIiEgkBYSIiERSQIiISCQFhIiIRFJAiIhIJAWEiIhEajXfgxCR9Lg77lDlTjIcTrpTlXSSHoyvNezBcDK5bVqHmnk9fF0zzsGpHhcMJ2tNV72cbW3JYMLay01pr9sW3CFoWxtQe73heogaV2d8uKg684bzpa4j5X3WbMda025rT11v6nJqTxe0p06XOn/d91bfcnCnT7cOnHPwgB381XeNAkIkxdbKJJsrqti8tYpNWyvZXFHFlsokVUmnoipJZZVTmax+Dtqqkk5llVOR0l5Zlaw1vqJqW1v1/BVVTlUySUX19NXzJpPhuKC9erjKnWQy2KknHaqSjlcP+7bh6p29Rw2719oZSeswcsAeCgiRyqokm8IdeLATr2JzRSWbtyZrduibwnHBcCWbtlZRHrbXHd5cZ57KZOPvPc0gJ5EgO8vIThjZWQmyE0ZOVtCWlbDI8R1ysshqn01OOE12IoEZZCWMhFkwbMFwIgFmFr4OhxPBcDA+ZbjmQdhez3Qpw1nh+ixl2urXFr7HRMrwtvbqesCovYxtr7cN1yw3nLfuchNmNdu07vzb2oNn2LYsqF1r9bypf6P6xoeL2ra+cFnV41LXX/NUZ72p04aV1UxXq4Y67XXXlVprU1BASGyqks6qDVtYvq6c5WvL+XxdeTi8hc/XlVO2cWvKzryS8ookW6sa9quVCYOO7bLp0C6Lju2y6JCTVTPcvWO7YDilbdv4bDq0S9AhJ5v2OcEOOzuRICdr2w482KEnanbgOVnbpsvOCsbnJBIkEk3zn1mksSkgJCM2ba1k+dpgh/95yk4/te2L9VuoqvOJPSth7NmlPb275tK3W27Njrtju2xyc6qHg514h5zq4eyU4do7+nZZiSb7tCXS2iggpEGSSWflxi18vjb85L+unM9rBUEwvL68crt5u7TPpne3XPp0zWXvvXvRp1t7+nTNpXfXXPqE7T07tydLn7hFmgUFhNRSXlFF8dI1NTv61FM/n68NPvXXPU+fMNizSy69u+UyOK8Th+3dsyYI+nTNrRnu1F7/3ERaEv2PFdydWUtWM312Cc/OX8b6Lds+/Xdun03vru3p0y2XQ/buGez0u4Wf+sPhXvrUL9IqKSDasKVlm5g+p4Qn55TyadkmOrbL4rihfTl+WB8G9OhEn265dNanfpE2K6P/+81sHHAXkAXc7+63RUxzBnATwfc+5rr7OWH7+cAN4WS3uvtDmay1rVhfXsGz85cxfXYpby0pwwwOHdyTy44awrihfXQaSERqZGxvYGZZwD3A0UAJMMvMZrj7wpRphgDXAV9x99VmtmfY3gP4KVBIEByzw3lXZ6re1qwq6fxr0Uqmzynh+QXLKa9IMqhXJ64+Zl9OGVVA/h4d4i5RRJqhTH5cHAMscvfFAGY2BRgPLEyZ5kLgnuodv7t/EbYfC7zg7mXhvC8A44DHM1hvq/Ph5+uZNqeEp98u5fN1W+iam82EUQVMGF3AyP57qPuniOxQJgMiH1ia8roEOLjONPsCmNm/CE5D3eTuz9Uzb37dFZjZRcBFAAMGNP7XzFui1Ru3MmPuZ0yfU8K8krVkJYwj9s3jpycW8PUv70luTlbcJYpICxH3CedsYAhwBFAAzDSzA9Od2d0nA5MBCgsL2+wdZrZWJnnl/S+YPqeEl977gooqZ7++Xbnh+P0YPyKfvC7t4y5RRFqgTAZEKdA/5XVB2JaqBPiPu1cAH5vZBwSBUUoQGqnzvpKxSlsgd+ed0nVMn1PCjLmfUbZxK706t+f8Qwdy6qgC9u/XNe4SRaSFy2RAzAKGmNkggh3+WcA5daZ5GjgbeNDMehGccloMfAT8t5l1D6c7huBidpv3+bpynn67lOlzSvjg8w20y0pw9P69mTA6n7FD8sjO0k98iEjjyFhAuHulmV0CPE9wfeEBd19gZjcDRe4+Ixx3jJktBKqAH7r7KgAzu4UgZABurr5g3RaVV1Tx/ILlTJ9TyusfriDpMGrAHtx68lBOHNaPbh1z4i5RRFoh81Zyc/jCwkIvKiqKu4xG4+4UfRJ8u/mZecG3m/t1y+XUUQWcOiqfwXmd4y5RRFoBM5vt7oVR4+K+SC111Pft5gmj8jlkcE/dOlpEmowCoplYtnYzV06dyxuLV+nbzSLSLGjP0wxUJZ3LphTzTulafbtZRJoNBUQzcO+rH/HWx2XcftowTi/sv/MZRESagPpExqx46RrufOEDThjWl9NGF8RdjohIDQVEjDZsqeSyKW/Tu2suPz/lQN0bSUSaFZ1iitFNMxawtGwTUy46lG4d9F0GEWledAQRk7/O/Yxps0v4/pH7MGZQj7jLERHZjgIiBiWrN3H9U/MZOWAPfnDUkLjLERGJpIBoYlVJ58qpc3GHu84cSY7unSQizZSuQTSx/3l5EW8tKeOOM4YzoGfHuMsREamXPr42odmfrOa3//yQk4b345SR2/3+kYhIs6KAaCLryyu4fOrb9O2Wy62nDFWXVhFp9nSKqYn89C8LKF29mSe+eyhdc9WlVUSaPx1BNIG/FJfy5NulXPr1IRQOVJdWEWkZFBAZtrRsEzc89Q6j9+rOpV/fJ+5yRETSpoDIoMqqJJdPLQbgt2eO0M+BikiLomsQGfT7lxcx+5PV3HXWCPr3UJdWEWlZ9JE2Q2Z/Usbd//yQU0bmM36EurSKSMujgMiAdeUVXDalmPzuHbh5/AFxlyMiskt0iikDfvL0OyxbW84T3z2ULurSKiItlI4gGtlTb5fwdPFnXHbUEEbv1T3uckREdpkCohF9umoTNz69gIMGduf7R6pLq4i0bAqIRhJ0aX0bM7jzzBFkJXQrDRFp2XQNopHc/dIi5ny6hrvPHklBd3VpFZGWT0cQjWDWkjJ+/9KHTBhVwEnD+8VdjohIo1BA7Ka1myu4fEox/Xt05Gfq0ioirYhOMe0Gd+eGp99h+bpypl18KJ3ba3OKSOuhI4jd8OScUv469zOu+K8hjBygLq0i0rooIHbRJ6s28pO/vMOYQT34f0eoS6uItD4KiF1QUZXksinFZCVMXVpFpNXSSfNdcNeLH1K8dA33nDOK/D06xF2OiEhG6Aiigf6zeBX3vLKI00cXcPywvnGXIyKSMQqIBli7qYIrphazV4+O3HSSurSKSOumU0xpcneuf3o+X6zfwvT/dxid1KVVRFq5jB5BmNk4M3vfzBaZ2bUR4yea2QozKw4fF6SMq0ppn5HJOtPx59klPDNvGVcesy/D++8RdzkiIhmXsY/BZpYF3AMcDZQAs8xshrsvrDPpVHe/JGIRm919RKbqa4iPV27kphkLOGRwD747du+4yxERaRKZPIIYAyxy98XuvhWYAozP4PoyoqIqyeVT3iYnK6EurSLSpmQyIPKBpSmvS8K2uiaY2Twzm2Zm/VPac82syMzeNLOTo1ZgZheF0xStWLGiEUvf5s4XPmBuyVpuO/VA+nZTl1YRaTvi7sX0V2Cguw8DXgAeShm3l7sXAucAvzWz7c7tuPtkdy9098K8vLxGL+6Nj1bxh1c/4qyD+nPcgerSKiJtSyYDohRIPSIoCNtquPsqd98SvrwfGJ0yrjR8Xgy8AozMYK3bWbNpK1dMLWZQz0785MT9m3LVIiLNQiYDYhYwxMwGmVk74CygVm8kM0v9WH4S8G7Y3t3M2ofDvYCvAHUvbmeMu3Pdk/NZtXELd501ko7t1KVVRNqejO353L3SzC4BngeygAfcfYGZ3QwUufsM4AdmdhJQCZQBE8PZ9wPuM7MkQYjdFtH7KWOeKFrK399ZzrXHfZkDC7o11WpFRJoVc/e4a2gUhYWFXlRUtNvLWbxiA8ff/TojB+zBI985mIR6LYlIK2Zms8PrvduJ+yJ1s7K1MrhLa/ucBHecMULhICJtmk6up/jNC+8zv3Qt9503mj7dcuMuR0QkVjqCCP170Uomz1zM2WMGcOwBfeIuR0QkdgoIYPXGrVzxRDGDe3XixhP2i7scEZFmoc2fYnJ3rn1yHmUbt/LH8w9Sl1YRkVCbP4JYvHIjMz9YyTXHfpmh+erSKiJSrc1/XN47rzP/uGKsfjpURKSONh8QAP17dIy7BBGRZqfNn2ISEZFoCggREYmkgBARkUgKCBERiaSAEBGRSAoIERGJpIAQEZFICggREYmkgBARkUgKCBERiaSAEBGRSAoIERGJpIAQEZFICggREYmk232LSItQUVFBSUkJ5eXlcZfSIuXm5lJQUEBOTk7a8yggRKRFKCkpoUuXLgwcOBAzi7ucFsXdWbVqFSUlJQwaNCjt+XSKSURahPLycnr27Klw2AVmRs+ePRt89KWAEJEWQ+Gw63Zl2ykgREQkkgJCRKSZqaysjLsEQAEhItIgJ598MqNHj+aAAw5g8uTJADz33HOMGjWK4cOHc9RRRwGwYcMGJk2axIEHHsiwYcOYPn06AJ07d65Z1rRp05g4cSIAEydO5OKLL+bggw/mmmuu4a233uLQQw9l5MiRHHbYYbz//vsAVFVVcfXVVzN06FCGDRvG7373O1566SVOPvnkmuW+8MILnHLKKbv9XtWLSURanJ/9dQELP1vXqMvcv19XfnriATud7oEHHqBHjx5s3ryZgw46iPHjx3PhhRcyc+ZMBg0aRFlZGQC33HIL3bp1Y/78+QCsXr16p8suKSnh3//+N1lZWaxbt47XXnuN7OxsXnzxRa6//nqmT5/O5MmTWbJkCcXFxWRnZ1NWVkb37t353ve+x4oVK8jLy+PBBx/k29/+9u5tEBQQIiINcvfdd/PUU08BsHTpUiZPnszYsWNruo/26NEDgBdffJEpU6bUzNe9e/edLvv0008nKysLgLVr13L++efz4YcfYmZUVFTULPfiiy8mOzu71vrOO+88HnnkESZNmsQbb7zBww8/vNvvVQEhIi1OOp/0M+GVV17hxRdf5I033qBjx44cccQRjBgxgvfeey/tZaT2Jqrb7bRTp041wzfeeCNHHnkkTz31FEuWLOGII47Y4XInTZrEiSeeSG5uLqeffnpNgOyOtK5BmNllZtbVAn80szlmdsxur11EpAVZu3Yt3bt3p2PHjrz33nu8+eablJeXM3PmTD7++GOAmlNMRx99NPfcc0/NvNWnmHr37s27775LMpmsORKpb135+fkA/OlPf6ppP/roo7nvvvtqLmRXr69fv37069ePW2+9lUmTJjXK+033IvW33X0dcAzQHTgPuK1RKhARaSHGjRtHZWUl++23H9deey2HHHIIeXl5TJ48mVNPPZXhw4dz5plnAnDDDTewevVqhg4dyvDhw3n55ZcBuO222zjhhBM47LDD6Nu3b73ruuaaa7juuusYOXJkrV5NF1xwAQMGDGDYsGEMHz6cxx57rGbcN7/5Tfr3789+++3XKO/X3H3nE5nNc/dhZnYX8Iq7P2Vmb7v7yEapohEUFhZ6UVFR3GWISIa8++67jbbja60uueQSRo4cyXe+853I8VHb0Mxmu3th1PTpHkHMNrN/AN8AnjezLkByZzOZ2Tgze9/MFpnZtRHjJ5rZCjMrDh8XpIw738w+DB/np1mniEibNHr0aObNm8e5557baMtM9yrGd4ARwGJ332RmPYAdnuQysyzgHuBooASYZWYz3H1hnUmnuvsldebtAfwUKAScIKBmuPvO+4mJiLRBs2fPbvRlpnsEcSjwvruvMbNzgRuAtTuZZwywyN0Xu/tWYAowPs31HQu84O5lYSi8AIxLc14REWkE6QbEH4BNZjYcuAr4CNhZJ9t8YGnK65Kwra4JZjbPzKaZWf+GzGtmF5lZkZkVrVixIs23IiIi6Ug3ICo9uJo9Hvi9u98DdGmE9f8VGOjuwwiOEh5qyMzuPtndC929MC8vrxHKERGRaukGxHozu46ge+szZpYAdvazRKVA/5TXBWFbDXdf5e5bwpf3A6PTnVdERDIr3YA4E9hC8H2I5QQ77Nt3Ms8sYIiZDTKzdsBZwIzUCcwstRPwScC74fDzwDFm1t3MuhN8/+L5NGsVEcmI1BvttQVp9WJy9+Vm9ihwkJmdALzl7ju8BuHulWZ2CcGOPQt4wN0XmNnNQJG7zwB+YGYnAZVAGTAxnLfMzG4hCBmAm929bBfen4iI7KJ0b7VxBvAWcDpwBvAfMzttZ/O5+7Puvq+77+3uPw/bfhKGA+5+nbsf4O7D3f1Id38vZd4H3H2f8PHgrrw5EZFMcHd++MMfMnToUA488ECmTp0KwLJlyxg7diwjRoxg6NChvPbaa1RVVTFx4sSaae+8886Yq09fut+D+DFwkLt/AWBmecCLwLRMFSYiUq+/XwvL5zfuMvscCMeldwehJ598kuLiYubOncvKlSs56KCDGDt2LI899hjHHnssP/7xj6mqqmLTpk0UFxdTWlrKO++8A8CaNWsat+4MSvcaRKI6HEKrGjCviEir8vrrr3P22WeTlZVF7969+drXvsasWbM46KCDePDBB7npppuYP38+Xbp0YfDgwSxevJhLL72U5557jq5du8ZdftrSPYJ4zsyeBx4PX58JPJuZkkREdiLNT/pNbezYscycOZNnnnmGiRMncuWVV/Ktb32LuXPn8vzzz3PvvffyxBNP8MADD8RdalrSOgpw9x8Ck4Fh4WOyu/8ok4WJiDRXhx9+OFOnTqWqqooVK1Ywc+ZMxowZwyeffELv3r258MILueCCC5gzZw4rV64kmUwyYcIEbr31VubMmRN3+WlL+xcl3H06MD2DtYiItAinnHIKb7zxBsOHD8fM+NWvfkWfPn146KGHuP3228nJyaFz5848/PDDlJaWMmnSJJLJ4P6mv/jFL2KuPn07vN23ma0nuFnedqMAd/dmczJNt/sWad10u+/d19Dbfe/wCMLdG+N2GiIi0gKpJ5KIiERSQIiISCQFhIi0GOn8RLJE25Vtp4AQkRYhNzeXVatWKSR2gbuzatUqcnNzGzRf2t1cRUTiVFBQQElJCfpxsF2Tm5tLQUFBg+ZRQIhIi5CTk8OgQYPiLqNN0SkmERGJpIAQEZFICggREYmkgBARkUgKCBERiaSAEBGRSAoIERGJpIAQEZFICggREYmkgBARkUgKCBERiaSAEBGRSAoIgK2b4q5ARKTZUUCs+gh+XwjvPBl3JSIizYoCYo8B0KUv/PVyWLM07mpERJoNBURWDky4HzwJT14Eyaq4KxIRaRYUEAA9BsHxv4ZP/w2v3xF3NSIizYICotqwM2HoafDyL6CkKO5qRERip4CoZgYn3AFd82H6d6B8XdwViYjESgGRKrcbTPhfWPMp/P2auKsREYmVAqKuAYfA2Gtg7uMwf1rc1YiIxEYBEWXsD6H/wfC3K2H1J3FXIyISi4wGhJmNM7P3zWyRmV27g+kmmJmbWWH4eqCZbTaz4vBxbybr3E5WNpw6GfCg62tVZZOuXkSkOchYQJhZFnAPcBywP3C2me0fMV0X4DLgP3VGfeTuI8LHxZmqs17dB8Lxv4Glb8Jrv2ny1YuIxC2TRxBjgEXuvtjdtwJTgPER090C/BIoz2Atu2bYGXDgGfDqL2HpW3FXIyLSpDIZEPlA6r0rSsK2GmY2Cujv7s9EzD/IzN42s1fN7PCoFZjZRWZWZGZFK1asaLTCazn+19CtIOz6ujYz6xARaYZiu0htZgngDuCqiNHLgAHuPhK4EnjMzLrWncjdJ7t7obsX5uXlZabQ3G7BrTjWlsIzV2dmHSIizVAmA6IU6J/yuiBsq9YFGAq8YmZLgEOAGWZW6O5b3H0VgLvPBj4C9s1grTvWfwx87Ucw/wmY90RsZYiINKVMBsQsYIiZDTKzdsBZwIzqke6+1t17uftAdx8IvAmc5O5FZpYXXuTGzAYDQ4DFGax15w6/CvofEnZ9XRJrKSIiTSFjAeHulcAlwPPAu8AT7r7AzG42s5N2MvtYYJ6ZFQPTgIvdvSxTtaYlKzv4lrUlYPqF6voqIq2euXvcNTSKwsJCLypqgpvszZ8WXLD+2o/gyOszvz4RkQwys9nuXhg1Tt+kbqgDT4PhZ8PM2+GTN+KuRkQkYxQQu+Ibtwe/RPfkRbB5TdzViIhkhAJiV7TvAhP+COtK4ZmroJWcphMRSaWA2FUFhXDkdfDONJg3Ne5qREQanQJid3z1StjrK8FRRFm8vXBFRBqbAmJ3JLLglPuC5+kXQlVF3BWJiDQaBcTu2qM/nPBbKC0KbuonItJKKCAaw9BTYcQ3g9uCL/lX3NWIiDQKBURjOe6XwW9IPHkRbF4ddzUiIrtNAdFY2ncJ7vq6YTn87Qp1fRWRFk8B0ZjyRwe331jwFBQ/Fnc1IiK7RQHR2L5yOez1VXj2h7Dqo7irERHZZQqIxpbIglPvg6wcmH6Bur6KSIulgMiEbgVw4l3w2Rx4+b/jrkZEZJcoIDLlgJNh5Hnw+p3w8WtxVyMi0mAKiEwadxv0GAxPfRc2xft7RyIiDaWAyKT2ncOur5/D3y5X11cRaVEUEJmWPwq+fiMs/Au8/X9xVyMikjYFRFM47AcwaCz8/UewclHc1YiIpEUB0RQSieCur9ntg9+zrtwad0UiIjulgGgqXfvBSb+DZcXw8s/jrkZEZKcUEE1pvxNh1Pnwr7tg8atxVyMiskMKiKY27hfQcx91fRWRZk8B0dTadYLT/ggbV8KMS9X1VUSaLQVEHPoOh6N+Au/9DeY8FHc1IiKRFBBxOfQSGHwE/P1aWPFB3NWIiGxHARGXRAJOvhdyOoRdX7fEXZGISC0KiDh17Qvjfw/L58FLt8RdjYhILQqIuH35eCj8Nvz7d/DRy3FXIyJSQwHRHBzzc+j1JXjq4uCeTTrdJCLNgAKiOWjXMej6agl44lvwmy/BM1dByWx1gxWR2GTHXYCE+hwIl8+Hxa/A3Mfg7Udg1v3Qa18YfhYMOwu65cddpYi0Ieat5BNqYWGhFxUVxV1G4ylfCwuehrmPw6dvAAaDvwbDz2dGA4AAAAlySURBVIH9Tgi+cCcispvMbLa7F0aOU0C0AGWLYe6UICzWfArtOsP+JwdHFnt9JegyKyKyCxQQrUUyCZ/+OwiKBX+BrethjwHB6afhZ0HPveOuUERamB0FREY/eprZODN738wWmdm1O5hugpm5mRWmtF0Xzve+mR2byTpbjEQCBn4Vxt8DV38Ap/4v9NgbZt4OvxsFfzwWZv8pOD0lIrKbMnYEYWZZwAfA0UAJMAs4290X1pmuC/AM0A64xN2LzGx/4HFgDNAPeBHY192r6ltfmziCqM/aUpg3NTiyWPkBZOfCl74BI86BwUdClvoiiEi0uI4gxgCL3H2xu28FpgDjI6a7BfglUJ7SNh6Y4u5b3P1jYFG4PInSLR8OvxK+/xZc+BKMPA8WvwyPngZ37g//uAE+XxB3lSLSwmQyIPKBpSmvS8K2GmY2Cujv7s80dN5w/ovMrMjMilasWNE4VbdkZpA/Go7/NVz1Ppzxf8HrN/8AfzgM7j08GN64Mu5KRaQFiK37i5klgDuAq3Z1Ge4+2d0L3b0wLy+v8YprDbLbw/4nwdmPB2Ex7pdBgDx3bfBFvMfPhoUz9K1tEalXJk9OlwL9U14XhG3VugBDgVfMDKAPMMPMTkpjXmmITr3gkIuDx+cLgy/izXsC3n8WOnSHoROC71fkjwpCRESEzF6kzia4SH0Uwc59FnCOu0eeDDezV4Crw4vUBwCPse0i9T+BIbpI3YiqKoPrFHMfh/eegcry8FvbZ8MBJ0O3Abq4LdIG7Ogidcb2AO5eaWaXAM8DWcAD7r7AzG4Gitx9xg7mXWBmTwALgUrg+zsKB9kFWdkw5OjgsXkNLHwaih+Hf/4seFgCOveGLn2ha7/wuS906Vf7uX2XuN+JiGSIvignta36KLgf1PplsG4ZrP9s23PU9yvadQkDIzVI6gRK5z0hkdXkb0VEdi6WIwhpoXruXf83srduhPXLYd1nYYDUef74NdiwHJKVteezrOBopN4gCZ/bd878+xORtCkgJH3tOu04QCC4HcjGFbWPPNYt2xYkqxYFQbIl4mikfdfaRx6dekJOp+B26Dnho13HlLYO24/P6aAL7SKNRAEhjSuRgC69g0e/kfVPt3Xj9qewUp9XvgqbVgUXzxvEtgVFdZjkdAjCrSZgOtYzXGfa6uHs9pDIhkQOZOWEw9nbhhVI0kopICQe7TpBr32Cx44kk1Cxadtja/XzRqjYDBUbw7bU4dRpU8ZvWL79tFWN8D2Q6sBI5AQX/2sN59QOk+0Cpro9e/vhutNaVtB5IJEVhJIltrVVPxLVr632uESd6SLnqV6e1dNePUzwjG1b1w6Hbfv2mvl3NJzGclOfIWKdsjsUENK8JRLBtYlMXZ+oqoTKzduHSWrYVG4JrqskK4LpkxXB61rDdZ7TmbZiczhtdVvUtNXLqgBPAq2jU0nTigiPHQVLvePYyXwR66oZJo3p6ranM0/43HsonP5g2lskXQoIaduysiGrS8vpruseBIUnIVm1bdirh30H45LBEVlU+47GJVOXXRX+DK7XXh8eMez1tCdrz19rmOj2+taBp2RmnXXWPDd0HA2fL3Ie6ozzWk3Ry6pvnp1M130gmaCAEGlJqk8dkRWcdhLJIP0UmYiIRFJAiIhIJAWEiIhEUkCIiEgkBYSIiERSQIiISCQFhIiIRFJAiIhIpFbzexBmtgL4ZDcW0QtY2UjltHTaFrVpe9Sm7bFNa9gWe7l7XtSIVhMQu8vMiur70Yy2RtuiNm2P2rQ9tmnt20KnmEREJJICQkREIikgtpkcdwHNiLZFbdoetWl7bNOqt4WuQYiISCQdQYiISCQFhIiIRGrzAWFm48zsfTNbZGbXxl1PnMysv5m9bGYLzWyBmV0Wd01xM7MsM3vbzP4Wdy1xM7M9zGyamb1nZu+a2aFx1xQnM7si/H/yjpk9bma5cdfU2Np0QJhZFnAPcBywP3C2me0fb1WxqgSucvf9gUOA77fx7QFwGfBu3EU0E3cBz7n7l4HhtOHtYmb5wA+AQncfCmQBZ8VbVeNr0wEBjAEWuftid98KTAHGx1xTbNx9mbvPCYfXE+wA8uOtKj5mVgAcD9wfdy1xM7NuwFjgjwDuvtXd18RbVeyygQ5mlg10BD6LuZ5G19YDIh9YmvK6hDa8Q0xlZgOBkcB/4q0kVr8FrgGScRfSDAwCVgAPhqfc7jezTnEXFRd3LwV+DXwKLAPWuvs/4q2q8bX1gJAIZtYZmA5c7u7r4q4nDmZ2AvCFu8+Ou5ZmIhsYBfzB3UcCG4E2e83OzLoTnG0YBPQDOpnZufFW1fjaekCUAv1TXheEbW2WmeUQhMOj7v5k3PXE6CvASWa2hODU49fN7JF4S4pVCVDi7tVHlNMIAqOt+i/gY3df4e4VwJPAYTHX1OjaekDMAoaY2SAza0dwkWlGzDXFxsyM4Bzzu+5+R9z1xMndr3P3AncfSPDv4iV3b3WfENPl7suBpWb2pbDpKGBhjCXF7VPgEDPrGP6/OYpWeNE+O+4C4uTulWZ2CfA8QS+EB9x9QcxlxekrwHnAfDMrDtuud/dnY6xJmo9LgUfDD1OLgUkx1xMbd/+PmU0D5hD0/nubVnjbDd1qQ0REIrX1U0wiIlIPBYSIiERSQIiISCQFhIiIRFJAiIhIJAWESDNgZkfojrHS3CggREQkkgJCpAHM7Fwze8vMis3svvD3IjaY2Z3hbwP808zywmlHmNmbZjbPzJ4K79+Dme1jZi+a2Vwzm2Nme4eL75zyewuPht/QFYmNAkIkTWa2H3Am8BV3HwFUAd8EOgFF7n4A8Crw03CWh4EfufswYH5K+6PAPe4+nOD+PcvC9pHA5QS/TTKY4JvtIrFp07faEGmgo4DRwKzww30H4AuC24FPDad5BHgy/P2EPdz91bD9IeDPZtYFyHf3pwDcvRwgXN5b7l4Svi4GBgKvZ/5tiURTQIikz4CH3P26Wo1mN9aZblfvX7MlZbgK/f+UmOkUk0j6/gmcZmZ7AphZDzPbi+D/0WnhNOcAr7v7WmC1mR0etp8HvBr+Ul+JmZ0cLqO9mXVs0nchkiZ9QhFJk7svNLMbgH+YWQKoAL5P8OM5Y8JxXxBcpwA4H7g3DIDUu5+eB9xnZjeHyzi9Cd+GSNp0N1eR3WRmG9y9c9x1iDQ2nWISEZFIOoIQEZFIOoIQEZFICggREYmkgBARkUgKCBERiaSAEBGRSP8fZeWjN1GLPvsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wlDhO05EPP4"
      },
      "source": [
        "#test on data\n",
        "#write to csv\n",
        "with open('recoverd.csv', 'w') as f: \n",
        "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    for batch in test_dl:\n",
        "        input, _ = batch #only care about input\n",
        "        out = net(input) #forward pass\n",
        "\n",
        "        out = torch.squeeze(out, 1)\n",
        "        out = out.detach().numpy()\n",
        "        \n",
        "        for i in range(len(out)):\n",
        "            writer.writerow(out[i])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGV-cqnfNSV2"
      },
      "source": [
        "Debugging Section -- Ignore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtfqG0fBNRzQ"
      },
      "source": [
        "m = nn.Conv1d(16, 33, 3, stride=2)\n",
        "input = torch.randn(20, 16, 50)\n",
        "output = m(input)\n",
        "\n",
        "n = nn.BatchNorm1d(33)\n",
        "r = nn.ReLU()\n",
        "output_batch = n(output)\n",
        "out_relu = r(output_batch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9jWwOoZOUkR",
        "outputId": "9111c85d-01dd-4e30-900e-af8f44b460d2"
      },
      "source": [
        "print(input.shape)\n",
        "print(output.shape)\n",
        "print(output_batch.shape)\n",
        "print(out_relu.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 16, 50])\n",
            "torch.Size([20, 33, 24])\n",
            "torch.Size([20, 33, 24])\n",
            "torch.Size([20, 33, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frAAqa0EUYga",
        "outputId": "46949eed-73af-472d-e0ad-e30efe780561"
      },
      "source": [
        "x = torch.randn(5,10)\n",
        "x = torch.unsqueeze(x, 1)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JOfTUJ13zLs"
      },
      "source": [
        "#helper function for GPU\n",
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UytVFjyu30Np"
      },
      "source": [
        "#helper function for moving tensors to GPU\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmUs1wjC39_N"
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVgq0t7H4aUl"
      },
      "source": [
        "device = get_default_device()\n",
        "\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enzrK42B0nYd",
        "outputId": "119b22b5-199b-446a-d0a4-bf83a23f6732"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "6AS0E_M7yVW9",
        "outputId": "92785e46-26d3-4ed1-e1f1-614cc4248cf7"
      },
      "source": [
        "print(train_dl)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6e3efba2aaa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8cTbS2j-BDZ",
        "outputId": "a7150fd6-0d59-429b-d822-0f2dcd9a7b32"
      },
      "source": [
        "t3 = torch.tensor([[5., 6], \n",
        "                   [7, 8], \n",
        "                   [9, 10]])\n",
        "print(t3.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9VO40vs-E5g",
        "outputId": "9f122b80-346f-418b-9576-d7e1882ebd23"
      },
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13], \n",
        "     [13, 14, 15]], \n",
        "    [[15, 16, 17], \n",
        "     [17, 18, 19.]]])\n",
        "print(t4.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhTKmcXU_inu",
        "outputId": "a0a2c09b-d318-4384-9a59-17395224ea73"
      },
      "source": [
        "a = torch.zeros(10,20,100)\n",
        "print(a.shape)\n",
        "\n",
        "a = torch.reshape(a, (10,100,20))\n",
        "print(a.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 20, 100])\n",
            "torch.Size([10, 100, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWNB0cOzhtWQ",
        "outputId": "52b1ea9c-a96b-4808-f3df-a0f84fc35ffd"
      },
      "source": [
        "rnn = nn.LSTM(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "c0 = torch.randn(2, 3, 20)\n",
        "output, (hn, cn) = rnn(input, (h0, c0))\n",
        "print(output.shape)\n",
        "\n",
        "\n",
        "h_n, c_n = rnn(input, (h0, c0))\n",
        "print(h_n.shape)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 20])\n",
            "torch.Size([5, 3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4g-spBFeoLq"
      },
      "source": [
        " '''\n",
        "        self.layers2 = nn.Sequential(\n",
        "            nn.Conv1d(20, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 1, 1)\n",
        "\n",
        "            \n",
        "            nn.Conv1d(20, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "        )\n",
        "        '''\n",
        "\n",
        " #Conv2\n",
        "            nn.Conv1d(10, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(20, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA_MijnbZw_R",
        "outputId": "8bfc8d30-5420-440d-fe81-406e477e391c"
      },
      "source": [
        "a = torch.zeros(10,1,100)\n",
        "a = torch.squeeze(a, 1)\n",
        "a.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    }
  ]
}