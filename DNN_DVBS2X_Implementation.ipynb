{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN DVBS2X Implementation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG851CQXAexf"
      },
      "source": [
        "#to do \n",
        "#LSTM -- done\n",
        "#use GPU for training -- (issues with input and model being on different devices)\n",
        "#stack real and imaginary into one array -- (done)\n",
        "#train \n",
        "#test\n",
        "#import back to matlab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqy9OHMcQmDS"
      },
      "source": [
        "#import libraries \n",
        "import numpy as np\n",
        "\n",
        "#pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
        "\n",
        "#for reading from csv\n",
        "import csv \n",
        "\n",
        "#for plotting \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ipw6bAIucuj"
      },
      "source": [
        "#read input and labels into variables \n",
        "with open('train.csv', 'r') as f: \n",
        "    data = list(csv.reader(f, delimiter=\",\"))\n",
        "\n",
        "data = np.array(data, dtype = 'float32') #convert to numpy array\n",
        "data = torch.from_numpy(data) #convert to torch tensor\n",
        "\n",
        "with open('labels.csv', 'r') as f:\n",
        "    labels = list(csv.reader(f, delimiter=\",\"))\n",
        "\n",
        "labels = np.array(data, dtype = 'float32') #convert to numpy array\n",
        "labels = torch.from_numpy(labels) #convert to torch tensor "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80yYn4kC8EoA"
      },
      "source": [
        "#create a custom dataset with input and labels \n",
        "class CustomDS(Dataset):\n",
        "    def __init__(self, input, labels):\n",
        "        self.labels = labels\n",
        "        self.input = input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        data = self.input[idx]\n",
        "        return data, label"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClXRw-Wnt4XN"
      },
      "source": [
        "ds = CustomDS(data, labels) #create a dataset with (corrupted) input and corresponding labels\n",
        "length = len(ds) \n",
        "train_size = int(0.5*length) \n",
        "val_size, test_size = int(0.25*length), int(0.25*length)\n",
        "\n",
        "#get train, validation, and test sets\n",
        "train_ds, val_ds, test_ds = random_split(ds, [train_size, val_size, test_size])\n",
        "\n",
        "#create data loaders\n",
        "batch_size = 10; \n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
        "val_dl = DataLoader(val_ds, batch_size, shuffle = True)\n",
        "test_dl = DataLoader(test_ds, batch_size, shuffle = True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuVCptcFxYWm"
      },
      "source": [
        "#define NN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self): \n",
        "    #layer definition here\n",
        "        super().__init__()\n",
        "        self.layers1 = nn.Sequential(\n",
        "            #Conv1\n",
        "            nn.Conv1d(1, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #Conv2\n",
        "            nn.Conv1d(10, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(20, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.lstm1 = nn.LSTM(20, 10, 1, batch_first = True)\n",
        "        self.lstm2 = nn.LSTM(10, 5, 1, batch_first = True)\n",
        "        self.lstm3 = nn.LSTM(5, 10, 1, batch_first = True)\n",
        "        self.lstm4 = nn.LSTM(10, 20, 1, batch_first = True)\n",
        "        \n",
        "        self.layers2 = nn.Sequential(\n",
        "            #Conv3\n",
        "            nn.Conv1d(20, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #Conv4\n",
        "            nn.Conv1d(10, 1, 1)\n",
        "        )   \n",
        "       \n",
        "    def forward(self, x): \n",
        "        x = torch.unsqueeze(x, 1) #need this so input is of size (N, Cin, L)\n",
        "        #define hidden state and cell state\n",
        "\n",
        "        #lstm1\n",
        "        h_0 = torch.zeros(1, 10, 10) #(num_layers, batch_size, hidden_state)\n",
        "        c_0 = torch.zeros(1, 10, 10)\n",
        "\n",
        "        h_1 = torch.zeros(1,10, 5)\n",
        "        c_1 = torch.zeros(1,10,5)\n",
        "\n",
        "        h_2 = torch.zeros(1,10, 10)\n",
        "        c_2 = torch.zeros(1, 10, 10)\n",
        "\n",
        "        h_3 = torch.zeros(1, 10, 20)\n",
        "        c_3 = torch.zeros(1, 10, 20)\n",
        "        \n",
        "        out = self.layers1(x) #convolution\n",
        "\n",
        "        out = torch.reshape(out, (10, 100, 20))\n",
        "        \n",
        "        out, (h_n, c_n) = self.lstm1(out, (h_0, c_0)) #pass through lstm1 (h_n = [1,10,10])\n",
        "\n",
        "        out,(h_n, c_n) = self.lstm2(out, (h_1, c_1))\n",
        "\n",
        "        out,(h_n, c_n) = self.lstm3(out, (h_2, c_2))\n",
        "\n",
        "        out, (h_n, c_n) = self.lstm4(out, (h_3, c_3))\n",
        "\n",
        "        out = torch.reshape(out, (10, 20, 100))\n",
        "    \n",
        "        out = self.layers2(out) #convolution\n",
        "        return out\n",
        "\n",
        "    def training_step(self, x):\n",
        "        inputs, labels = x #get input and labels from batch of data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        out = self(inputs) #forward pass\n",
        "        loss = F.mse_loss(out, labels) #loss calculation\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, x):\n",
        "        inputs, labels = x #get input and labels from batch of data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        out = self(inputs) #forward pass\n",
        "        loss = F.mse_loss(out,labels) #loss calculation\n",
        "        acc = 1-loss #accuracy calculation\n",
        "\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs): \n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean() #Co\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()\n",
        "        \n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RqFJIixrmNG"
      },
      "source": [
        "def evaluate(model, val_dl):\n",
        "    outputs = [model.validation_step(batch) for batch in val_dl]\n",
        "    \n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oplXuZa241CL"
      },
      "source": [
        "def trainNet(epochs, lr, model, train_dl, val_dl, opt_func = torch.optim.SGD): \n",
        "    #training function for training NN\n",
        "    #inputs: \n",
        "    #epochs: number of epochs to train for\n",
        "    #lr: learning rate for optimizer\n",
        "    #model: model to be traine on\n",
        "    #train_dl: data loader with inputs and labels to train on\n",
        "    #val_dl: validation loader \n",
        "    #opt_func: optimizer function\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    history = [] #recording epoch-wise results\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "    #enter training loop\n",
        "        for batch in train_dl:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward() #backprop\n",
        "            optimizer.step() #step forward in optimizer based on backgrop results\n",
        "            optimizer.zero_grad() #zero the gradients from training step\n",
        "\n",
        "        #validation phase\n",
        "        result = evaluate(model, val_dl)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "\n",
        "    return history\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR698MeB4CEq"
      },
      "source": [
        "net = Net() #instantiate \n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYSPxBZlAb4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f188104-6a71-4565-f7b4-19774f16be00"
      },
      "source": [
        "history = trainNet(1, 0.001, net, train_dl, val_dl)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Using a target size (torch.Size([10, 100])) that is different to the input size (torch.Size([10, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: Using a target size (torch.Size([10, 100])) that is different to the input size (torch.Size([10, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 0.3971, val_acc: 0.6029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "i9BOGqzD1ITk",
        "outputId": "9693fd1b-aac4-44b5-8c90-72b12bcc5f1d"
      },
      "source": [
        "#plot training results\n",
        "accuracies = [result['val_acc'] for result in history]\n",
        "plt.plot(accuracies, label = 'accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "losses = [result['val_loss'] for result in history]\n",
        "plt.plot(losses, label = 'loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0443993410>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGV-cqnfNSV2"
      },
      "source": [
        "Debugging Section -- Ignore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtfqG0fBNRzQ"
      },
      "source": [
        "m = nn.Conv1d(16, 33, 3, stride=2)\n",
        "input = torch.randn(20, 16, 50)\n",
        "output = m(input)\n",
        "\n",
        "n = nn.BatchNorm1d(33)\n",
        "r = nn.ReLU()\n",
        "output_batch = n(output)\n",
        "out_relu = r(output_batch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9jWwOoZOUkR",
        "outputId": "9111c85d-01dd-4e30-900e-af8f44b460d2"
      },
      "source": [
        "print(input.shape)\n",
        "print(output.shape)\n",
        "print(output_batch.shape)\n",
        "print(out_relu.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 16, 50])\n",
            "torch.Size([20, 33, 24])\n",
            "torch.Size([20, 33, 24])\n",
            "torch.Size([20, 33, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frAAqa0EUYga",
        "outputId": "46949eed-73af-472d-e0ad-e30efe780561"
      },
      "source": [
        "x = torch.randn(5,10)\n",
        "x = torch.unsqueeze(x, 1)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JOfTUJ13zLs"
      },
      "source": [
        "#helper function for GPU\n",
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UytVFjyu30Np"
      },
      "source": [
        "#helper function for moving tensors to GPU\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmUs1wjC39_N"
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVgq0t7H4aUl"
      },
      "source": [
        "device = get_default_device()\n",
        "\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enzrK42B0nYd",
        "outputId": "119b22b5-199b-446a-d0a4-bf83a23f6732"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "6AS0E_M7yVW9",
        "outputId": "92785e46-26d3-4ed1-e1f1-614cc4248cf7"
      },
      "source": [
        "print(train_dl)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6e3efba2aaa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8cTbS2j-BDZ",
        "outputId": "a7150fd6-0d59-429b-d822-0f2dcd9a7b32"
      },
      "source": [
        "t3 = torch.tensor([[5., 6], \n",
        "                   [7, 8], \n",
        "                   [9, 10]])\n",
        "print(t3.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9VO40vs-E5g",
        "outputId": "9f122b80-346f-418b-9576-d7e1882ebd23"
      },
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13], \n",
        "     [13, 14, 15]], \n",
        "    [[15, 16, 17], \n",
        "     [17, 18, 19.]]])\n",
        "print(t4.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhTKmcXU_inu",
        "outputId": "a0a2c09b-d318-4384-9a59-17395224ea73"
      },
      "source": [
        "a = torch.zeros(10,20,100)\n",
        "print(a.shape)\n",
        "\n",
        "a = torch.reshape(a, (10,100,20))\n",
        "print(a.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 20, 100])\n",
            "torch.Size([10, 100, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWNB0cOzhtWQ",
        "outputId": "52b1ea9c-a96b-4808-f3df-a0f84fc35ffd"
      },
      "source": [
        "rnn = nn.LSTM(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "c0 = torch.randn(2, 3, 20)\n",
        "output, (hn, cn) = rnn(input, (h0, c0))\n",
        "print(output.shape)\n",
        "\n",
        "\n",
        "h_n, c_n = rnn(input, (h0, c0))\n",
        "print(h_n.shape)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 20])\n",
            "torch.Size([5, 3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4g-spBFeoLq"
      },
      "source": [
        " '''\n",
        "        self.layers2 = nn.Sequential(\n",
        "            nn.Conv1d(20, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 1, 1)\n",
        "\n",
        "            \n",
        "            nn.Conv1d(20, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "        )\n",
        "        '''\n",
        "\n",
        " #Conv2\n",
        "            nn.Conv1d(10, 20, 1),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(20, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(10, 10, 1),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}